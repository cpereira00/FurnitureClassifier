{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import models\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "dataset_dir = './Dataset'\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "val_dir = os.path.join(dataset_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the image is (80,80,3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join(train_dir, 'sofa/2 Seater Sofa.jpg'))\n",
    "\n",
    "WIDTH,HEIGHT, CHANNELS = img.shape\n",
    "print(f'the size of the image is ({WIDTH},{HEIGHT},{CHANNELS})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_data_pipelines(batch_size, train_data_path, val_data_path, test_data_path):\n",
    "    \n",
    "    # Generators to augment data\n",
    "    train_augmentor = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_generator = train_augmentor.flow_from_directory(\n",
    "        train_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(80,80),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_augmentor = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "    )\n",
    "\n",
    "    val_generator = val_augmentor.flow_from_directory(\n",
    "        batch_size=batch_size,\n",
    "        directory=val_dir,\n",
    "        target_size=(80,80),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    test_generator = val_augmentor.flow_from_directory(\n",
    "        test_data_path,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(80,80),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, use transfer learning since small dataset \n",
    "def build_model():\n",
    "    base_model = InceptionV3(weights='imagenet',include_top=False, input_shape=(80,80,3))\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # dont update base model params\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images belonging to 3 classes.\n",
      "Found 30 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 1, 1, 2048)        21802784  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,328,099\n",
      "Trainable params: 525,315\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 4s 119ms/step - loss: 1.3908 - accuracy: 0.3952 - val_loss: 0.8408 - val_accuracy: 0.5667\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 1.0822 - accuracy: 0.5190 - val_loss: 0.6672 - val_accuracy: 0.6333\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.8168 - accuracy: 0.6762 - val_loss: 0.5658 - val_accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.8999 - accuracy: 0.6381 - val_loss: 0.5210 - val_accuracy: 0.7667\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.7752 - accuracy: 0.6524 - val_loss: 0.4863 - val_accuracy: 0.7667\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.6582 - accuracy: 0.7190 - val_loss: 0.4583 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.6434 - accuracy: 0.7286 - val_loss: 0.4274 - val_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5969 - accuracy: 0.7571 - val_loss: 0.3989 - val_accuracy: 0.8333\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.5125 - accuracy: 0.8238 - val_loss: 0.3721 - val_accuracy: 0.8667\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.6602 - accuracy: 0.7381 - val_loss: 0.3661 - val_accuracy: 0.8667\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.5437 - accuracy: 0.7952 - val_loss: 0.3481 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.5210 - accuracy: 0.7905 - val_loss: 0.3460 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.5396 - accuracy: 0.7762 - val_loss: 0.3463 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.5154 - accuracy: 0.8095 - val_loss: 0.3426 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5185 - accuracy: 0.8143 - val_loss: 0.3547 - val_accuracy: 0.8667\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.5083 - accuracy: 0.8095 - val_loss: 0.3357 - val_accuracy: 0.8667\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.5180 - accuracy: 0.7952 - val_loss: 0.3435 - val_accuracy: 0.9000\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.5219 - accuracy: 0.7857 - val_loss: 0.3309 - val_accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.4708 - accuracy: 0.8048 - val_loss: 0.3431 - val_accuracy: 0.8667\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4592 - accuracy: 0.8333 - val_loss: 0.3374 - val_accuracy: 0.8667\n",
      "[INFO] Evaluation phase...\n",
      "4/4 [==============================] - 1s 37ms/step\n",
      "[INFO] Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bed       0.85      0.85      0.85        20\n",
      "       chair       0.72      0.90      0.80        20\n",
      "        sofa       0.73      0.55      0.63        20\n",
      "\n",
      "    accuracy                           0.77        60\n",
      "   macro avg       0.77      0.77      0.76        60\n",
      "weighted avg       0.77      0.77      0.76        60\n",
      "\n",
      "[INFO] Confusion matrix :\n",
      "[[17  0  3]\n",
      " [ 1 18  1]\n",
      " [ 2  7 11]]\n"
     ]
    }
   ],
   "source": [
    "def train(path_to_data, batch_size=16, epochs=15, learning_rate=1e-4):\n",
    "    \n",
    "    dataset_dir = path_to_data\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    test_dir = os.path.join(dataset_dir, 'test')\n",
    "    val_dir = os.path.join(dataset_dir, 'val')\n",
    "\n",
    "    train_generator, val_generator, test_generator = build_data_pipelines(\n",
    "        batch_size=batch_size,\n",
    "        train_data_path=train_dir,\n",
    "        val_data_path=val_dir,\n",
    "        test_data_path=test_dir\n",
    "    )\n",
    "    \n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator)\n",
    "\n",
    "    \n",
    "    # prediction evaluation\n",
    "    print(\"[INFO] Evaluation phase...\")\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    # gives a array of the correct class that was predicted based on highest probability\n",
    "    predictions_idxs = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # contains metrics about eval phase, gives precision, accuracy , recall, F1-score and support\n",
    "    # eval_generator.classes-> ground truth\n",
    "    my_classification_report = classification_report(test_generator.classes, predictions_idxs,\n",
    "                                                     target_names=test_generator.class_indices.keys())\n",
    "\n",
    "    # helps to compare predictions of one class to another\n",
    "    # shows what the model predicted the images to be\n",
    "    my_confusion_matrix = confusion_matrix(test_generator.classes, predictions_idxs)\n",
    "\n",
    "    print(\"[INFO] Classification report :\")\n",
    "    print(my_classification_report)\n",
    "    print(\"[INFO] Confusion matrix :\")\n",
    "    print(my_confusion_matrix)\n",
    "    \n",
    "    model.save('deployment/saved_model/my_model.h5')\n",
    "\n",
    "train(path_to_data=dataset_dir,batch_size=15,epochs=20, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
