{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '_pywrap_tensorflow_internal' has no attribute 'TFE_NewContextOptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InceptionV3\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dropout, Flatten, Dense, Input\n",
      "File \u001b[1;32mc:\\users\\cpere\\pycharmprojects\\furnitureclassifier\\.venv\\lib\\site-packages\\tensorflow\\__init__.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_os\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;66;03m# Add `estimator` attribute to allow access to estimator APIs via\u001b[39;00m\n\u001b[0;32m     28\u001b[0m   \u001b[38;5;66;03m# \"tf.estimator...\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\cpere\\pycharmprojects\\furnitureclassifier\\.venv\\lib\\site-packages\\tensorflow\\python\\__init__.py:49\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# TODO(drpng): write up instructions for editing this file in a doc and point to\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# the doc instead.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# If you want to edit this file to expose modules in public tensorflow API, you\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m component_api_helper\n\u001b[0;32m     52\u001b[0m component_api_helper\u001b[38;5;241m.\u001b[39mpackage_hook(\n\u001b[0;32m     53\u001b[0m     parent_package_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow.python\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     54\u001b[0m     child_package_str\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow_estimator.python.estimator\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\users\\cpere\\pycharmprojects\\furnitureclassifier\\.venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:58\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _can_set_rtld_local:\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Ensure RTLD_LOCAL behavior for platforms where it isn't the default\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   \u001b[38;5;66;03m# (macOS). On Linux RTLD_LOCAL is 0, so this does nothing (and would not\u001b[39;00m\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;66;03m# override an RTLD_GLOBAL in _default_dlopen_flags).\u001b[39;00m\n\u001b[0;32m     56\u001b[0m   sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags \u001b[38;5;241m|\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mRTLD_LOCAL)\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __git_version__\n",
      "File \u001b[1;32mc:\\users\\cpere\\pycharmprojects\\furnitureclassifier\\.venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py:96\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTFE_NewContextOptions\u001b[39m():\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pywrap_tensorflow_internal\u001b[38;5;241m.\u001b[39mTFE_NewContextOptions()\n\u001b[1;32m---> 96\u001b[0m TFE_NewContextOptions \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_tensorflow_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_NewContextOptions\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTFE_ContextOptionsSetConfig\u001b[39m(options, proto):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pywrap_tensorflow_internal\u001b[38;5;241m.\u001b[39mTFE_ContextOptionsSetConfig(options, proto)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '_pywrap_tensorflow_internal' has no attribute 'TFE_NewContextOptions'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import models\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "dataset_dir = './Dataset'\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "val_dir = os.path.join(dataset_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mtrain_dir\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msofa/2 Seater Sofa.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msofa\u001b[39m\u001b[38;5;124m'\u001b[39m,img)\n\u001b[0;32m      3\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dir' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join(train_dir, 'sofa/2 Seater Sofa.jpg'))\n",
    "cv2.imshow('sofa',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "WIDTH,HEIGHT, CHANNELS = img.shape\n",
    "print(f'the size of the image is ({WIDTH},{HEIGHT},{CHANNELS})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_data_pipelines(batch_size, train_data_path, val_data_path, test_data_path):\n",
    "    \n",
    "    # Generators to augment data\n",
    "    train_augmentor = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_generator = train_augmentor.flow_from_directory(\n",
    "        train_dir,\n",
    "        batch_size=batch_size,\n",
    "        target_size=(80,80),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_augmentor = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "    )\n",
    "\n",
    "    val_generator = val_augmentor.flow_from_directory(\n",
    "        batch_size=batch_size,\n",
    "        directory=val_dir,\n",
    "        target_size=(80,80),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    test_generator = val_augmentor.flow_from_directory(\n",
    "        test_data_path,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(80,80),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, use transfer learning since small dataset \n",
    "def build_model():\n",
    "    base_model = InceptionV3(weights='imagenet',include_top=False, input_shape=(100,100,3))\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # dont update base model params\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images belonging to 3 classes.\n",
      "Found 30 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 1, 1, 2048)        21802784  \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,328,099\n",
      "Trainable params: 525,315\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 6s 212ms/step - loss: 1.4810 - accuracy: 0.4048 - val_loss: 0.9550 - val_accuracy: 0.5333\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 1.2589 - accuracy: 0.4286 - val_loss: 0.7338 - val_accuracy: 0.7000\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 1.0058 - accuracy: 0.5429 - val_loss: 0.5904 - val_accuracy: 0.7667\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.8492 - accuracy: 0.6714 - val_loss: 0.5410 - val_accuracy: 0.7667\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.8484 - accuracy: 0.6095 - val_loss: 0.4777 - val_accuracy: 0.8667\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.7519 - accuracy: 0.7095 - val_loss: 0.4500 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.7588 - accuracy: 0.6667 - val_loss: 0.4356 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.6554 - accuracy: 0.7286 - val_loss: 0.4066 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.6432 - accuracy: 0.7476 - val_loss: 0.3878 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.6137 - accuracy: 0.7667 - val_loss: 0.3808 - val_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.5157 - accuracy: 0.8095 - val_loss: 0.3677 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.5348 - accuracy: 0.8048 - val_loss: 0.3610 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.6070 - accuracy: 0.7714 - val_loss: 0.3616 - val_accuracy: 0.8667\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.5266 - accuracy: 0.7857 - val_loss: 0.3596 - val_accuracy: 0.8667\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4789 - accuracy: 0.8048 - val_loss: 0.3577 - val_accuracy: 0.9333\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.5259 - accuracy: 0.7619 - val_loss: 0.3571 - val_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.5576 - accuracy: 0.7952 - val_loss: 0.3727 - val_accuracy: 0.9000\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.5356 - accuracy: 0.7857 - val_loss: 0.3705 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.5077 - accuracy: 0.7810 - val_loss: 0.3526 - val_accuracy: 0.9333\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.5587 - accuracy: 0.7619 - val_loss: 0.3423 - val_accuracy: 0.9000\n",
      "[INFO] Evaluation phase...\n",
      "4/4 [==============================] - 1s 115ms/step\n",
      "[INFO] Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bed       0.75      0.90      0.82        20\n",
      "       chair       0.90      0.90      0.90        20\n",
      "        sofa       0.88      0.70      0.78        20\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.84      0.83      0.83        60\n",
      "weighted avg       0.84      0.83      0.83        60\n",
      "\n",
      "[INFO] Confusion matrix :\n",
      "[[18  0  2]\n",
      " [ 2 18  0]\n",
      " [ 4  2 14]]\n"
     ]
    }
   ],
   "source": [
    "def train(path_to_data, batch_size=16, epochs=15, learning_rate=1e-4):\n",
    "    \n",
    "    dataset_dir = path_to_data\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    test_dir = os.path.join(dataset_dir, 'test')\n",
    "    val_dir = os.path.join(dataset_dir, 'val')\n",
    "\n",
    "    train_generator, val_generator, test_generator = build_data_pipelines(\n",
    "        batch_size=batch_size,\n",
    "        train_data_path=train_dir,\n",
    "        val_data_path=val_dir,\n",
    "        test_data_path=test_dir\n",
    "    )\n",
    "    \n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator)\n",
    "\n",
    "    \n",
    "    # prediction evaluation\n",
    "    print(\"[INFO] Evaluation phase...\")\n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    # gives a array of the correct class that was predicted based on highest probability\n",
    "    predictions_idxs = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # contains metrics about eval phase, gives precision, accuracy , recall, F1-score and support\n",
    "    # eval_generator.classes-> ground truth\n",
    "    my_classification_report = classification_report(test_generator.classes, predictions_idxs,\n",
    "                                                     target_names=test_generator.class_indices.keys())\n",
    "\n",
    "    # helps to compare predictions of one class to another\n",
    "    # shows what the model predicted the images to be\n",
    "    my_confusion_matrix = confusion_matrix(test_generator.classes, predictions_idxs)\n",
    "\n",
    "    print(\"[INFO] Classification report :\")\n",
    "    print(my_classification_report)\n",
    "    print(\"[INFO] Confusion matrix :\")\n",
    "    print(my_confusion_matrix)\n",
    "    \n",
    "    model.save('deployment/saved_model/my_model.h5')\n",
    "\n",
    "train(path_to_data=dataset_dir,batch_size=15,epochs=20, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
